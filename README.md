<div align="center">
  <img src="public/logo_w_text.png" alt="SparrowAI Logo" width="400"/>
  
  <p align="center">
    <strong>A powerful, privacy-first AI chat application</strong>
    <br />
    Built with Tauri, React, and OpenVINO Model Server(OVMS) for lightning-fast local AI inference on Intel AIPC
    <br />
    <br />
    <a href="#-quick-start"><strong>Get Started Â»</strong></a>
    Â·
    <a href="#-features">Features</a>
    Â·
    <a href="#-screenshots">Screenshots</a>
    Â·
    <a href="https://github.com/zhengchy95/SparrowAI/issues">Report Bug</a>
    Â·
    <a href="https://github.com/zhengchy95/SparrowAI/issues">Request Feature</a>
  </p>

  <p align="center">
    <img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="MIT License"/>
    <img src="https://img.shields.io/badge/Tauri-2.0-24C8DB?logo=tauri" alt="Tauri"/>
    <img src="https://img.shields.io/badge/React-18.3-61DAFB?logo=react" alt="React"/>
    <img src="https://img.shields.io/badge/Rust-2021-000000?logo=rust" alt="Rust"/>
    <img src="https://img.shields.io/badge/OpenVINO Model Server-2025.2.1-0071C5" alt="OpenVINO"/>
  </p>
</div>

## ğŸš€ About SparrowAI

SparrowAI is a modern desktop application that brings powerful AI capabilities directly to your computer. Unlike cloud-based solutions, SparrowAI runs everything locally using Intel's OpenVINO Model Server for optimized performance, ensuring your conversations remain completely private.

### ğŸ¯ Key Highlights

- **ğŸ”’ 100% Local** - All processing happens on your device
- **âš¡ Optimized Performance** - Powered by Intel OpenVINO for maximum efficiency
- **ğŸ§  RAG Support** - Upload documents for context-aware conversations
- **ğŸ¨ Modern Interface** - Beautiful Material-UI design with dark/light themes

## âœ¨ Features

### ğŸ’¬ **Intelligent Conversations**

- Real-time streaming responses with performance metrics
- Multi-session chat management with persistent history
- Customizable system prompts and generation parameters
- Context-aware conversations with document upload support
- MCP (Model Context Protocol) integration for external tool access

### ğŸ“š **Document Intelligence (RAG)**

- Upload PDF, DOCX, XLSX files for enhanced context
- Automatic document processing and embedding generation
- Intelligent document chunking and retrieval
- File-based document management with expandable previews

### ğŸ¤– **Advanced Model Management**

- Browse and download models from Hugging Face Hub
- Automatic BGE model installation for RAG functionality
- Smart model pre-selection based on OVMS status
- Seamless model switching with configuration updates
- MCP server management and configuration

### âš¡ **High-Performance Infrastructure**

- Intel OpenVINO Model Server integration
- Automatic OVMS download and configuration
- Hardware acceleration (CPU/GPU/Neural Processing Unit)
- Efficient memory management and resource optimization

### ğŸ¨ **Polished User Experience**

- Material-UI design system with smooth animations
- Collapsible sidebar with session management
- Real-time initialization progress tracking
- Comprehensive settings with theme customization

## ğŸ“¸ Screenshots

> _Coming Soon - Beautiful interface screenshots showcasing the chat experience, document management, and model browser_

## ğŸš€ Quick Start

### Prerequisites

Make sure you have the following installed:

- **Node.js** 18+ ([Download](https://nodejs.org/))
- **Rust** latest stable ([Install](https://rustup.rs/))
- **pnpm** package manager (`npm install -g pnpm`)

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/DavidOzc/SparrowAI.git
   cd SparrowAI
   ```

2. **Install dependencies**

   ```bash
   pnpm install
   ```

3. **Run in development mode**

   ```bash
   pnpm tauri dev
   ```

4. **Build for production**
   ```bash
   pnpm tauri build
   ```

### First Launch

1. **Initialization** - SparrowAI will automatically:

   - Download OpenVINO Model Server
   - Install required BGE models for RAG
   - Create configuration files

2. **Download Models** - Visit the Models page to:

   - Browse Hugging Face OpenVINO models
   - Download your preferred language models
   - Models are stored in `~/.sparrow/models/`

3. **Start Chatting** - Select a model and begin conversations!

## ğŸ§  Core Technologies

### Frontend Stack

- **React 18** - Modern UI with hooks and concurrent features
- **Material-UI v7.2** - Comprehensive component library
- **Zustand** - Lightweight state management
- **Vite 6** - Lightning-fast development and builds

### Backend Stack

- **Rust** - Memory-safe systems programming
- **Tauri 2.0** - Secure desktop app framework
- **Tokio** - Asynchronous runtime
- **OpenVINO Model Server** - Optimized AI inference

### AI & ML Stack

- **OpenVINO** - Intel's AI optimization toolkit
- **BGE Embeddings** - Best-in-class text embeddings
- **Sled Database** - High-performance vector storage
- **Document Processing** - PDF, DOCX, XLSX support
- **MCP Integration** - Model Context Protocol for external tools

## ğŸ“ Project Structure

```
SparrowAI/
â”œâ”€â”€ src/                      # React frontend
â”‚   â”œâ”€â”€ components/          # UI components
â”‚   â”‚   â”œâ”€â”€ ChatPage.jsx    # Main chat interface
â”‚   â”‚   â”œâ”€â”€ DocumentsPage.jsx # RAG document manager
â”‚   â”‚   â”œâ”€â”€ ModelsPage.jsx   # Model browser
â”‚   â”‚   â”œâ”€â”€ McpPage.jsx     # MCP server management
â”‚   â”‚   â”œâ”€â”€ SettingsDialog.jsx # Application settings
â”‚   â”‚   â””â”€â”€ Sidebar.jsx     # Navigation sidebar
â”‚   â”œâ”€â”€ store/              # Zustand state stores
â”‚   â”‚   â”œâ”€â”€ useAppStore.jsx # Application state
â”‚   â”‚   â””â”€â”€ useChatStore.jsx # Chat state
â”‚   â””â”€â”€ hooks/              # Custom React hooks
â”œâ”€â”€ src-tauri/              # Rust backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ lib.rs          # Main application
â”‚   â”‚   â”œâ”€â”€ ovms.rs         # OVMS integration
â”‚   â”‚   â”œâ”€â”€ chat.rs         # Chat sessions
â”‚   â”‚   â”œâ”€â”€ huggingface.rs  # HF Hub integration
â”‚   â”‚   â”œâ”€â”€ mcp/            # MCP integration
â”‚   â”‚   â”‚   â”œâ”€â”€ client.rs   # MCP client
â”‚   â”‚   â”‚   â”œâ”€â”€ commands.rs # MCP commands
â”‚   â”‚   â”‚   â””â”€â”€ config.rs   # MCP configuration
â”‚   â”‚   â””â”€â”€ rag/            # RAG pipeline
â”‚   â”‚       â”œâ”€â”€ documents.rs
â”‚   â”‚       â”œâ”€â”€ embeddings.rs
â”‚   â”‚       â”œâ”€â”€ search.rs   # Vector search
â”‚   â”‚       â””â”€â”€ vector_store.rs
â”œâ”€â”€ public/                 # Static assets
â””â”€â”€ README.md              # You are here!
```

## âš™ï¸ Configuration

### Data Directory

SparrowAI stores all data in your user profile:

- **Windows**: `%USERPROFILE%\.sparrow\`

### Directory Structure

```
.sparrow/
â”œâ”€â”€ models/                 # Downloaded AI models
â”‚   â””â”€â”€ OpenVINO/          # OpenVINO optimized models
â”œâ”€â”€ ovms/                  # Model server installation
â”œâ”€â”€ vector_store/          # RAG document database
â””â”€â”€ chat_sessions.json     # Conversation history
```

## ğŸ¯ Usage Guide

### Model Recommendations

| Model                           | Size | Performance | Use Case                  |
| ------------------------------- | ---- | ----------- | ------------------------- |
| `Phi-3.5-mini-instruct-int4-ov` | ~2GB | âš¡âš¡âš¡      | Quick responses, coding   |
| `Qwen2.5-1.5B-Instruct-int4-ov` | ~1GB | âš¡âš¡âš¡      | Lightweight, multilingual |
| `Llama-3.1-8B-Instruct-int4-ov` | ~5GB | âš¡âš¡        | Complex reasoning         |

### RAG Document Support

Upload these document types for enhanced conversations:

- **PDF** - Research papers, books, manuals
- **DOCX** - Word documents, reports
- **XLSX** - Spreadsheets, data tables

### Advanced Settings

- **System Prompts** - Customize AI behavior and personality
- **Generation Parameters** - Fine-tune temperature, top-p, max tokens
- **RAG Settings** - Enable/disable retrieval augmented generation
- **Performance** - Monitor tokens per second and inference metrics

## ğŸ”§ Development

### Available Scripts

```bash
# Development
pnpm dev              # Start frontend dev server
pnpm tauri dev        # Launch Tauri development mode

# Building
pnpm build           # Build frontend for production
pnpm tauri build     # Create distributable app

# Testing
cd src-tauri && cargo test    # Run Rust tests
cd src-tauri && cargo check   # Check Rust code
```

### Contributing Guidelines

We welcome contributions! Please:

1. **Fork** the repository
2. **Create** a feature branch: `git checkout -b feature/amazing-feature`
3. **Commit** your changes: `git commit -m 'Add amazing feature'`
4. **Push** to the branch: `git push origin feature/amazing-feature`
5. **Open** a Pull Request

### Code Standards

- Follow Rust formatting: `cargo fmt`
- Apply Javascript formatting with prettier default config
- Update documentation for new features

## ğŸ” Troubleshooting

<details>
<summary><strong>ğŸ”§ Common Issues</strong></summary>

### OVMS Fails to Start

- Ensure Windows Defender/antivirus allows the app
- Check ports 1114-1115 are available
- Verify sufficient disk space (5GB+ recommended)

### Model Download Issues

- Check internet connection stability
- Verify Hugging Face Hub accessibility
- Try downloading smaller models first
- Clear browser cache if using web interface

### Performance Problems

- Monitor system resources (CPU/RAM/GPU)
- Use int4 quantized models for better performance
- Reduce max_tokens in settings
- Close unnecessary applications

### RAG Not Working

- Ensure BGE models are downloaded
- Check document upload file formats
- Verify sufficient storage space
- Try smaller documents first

</details>

## ğŸ“Š Performance Metrics

| Metric                  | Typical Range      | Optimized Hardware |
| ----------------------- | ------------------ | ------------------ |
| **Startup Time**        | 3-5 seconds        | < 2 seconds        |
| **Memory Usage**        | 200MB + model size | 150MB + model size |
| **Inference Speed**     | 5-30 tokens/sec    | 20-100+ tokens/sec |
| **Document Processing** | 1-5 MB/sec         | 5-15 MB/sec        |

_Performance varies by hardware configuration and model size_

## ğŸ”’ Privacy & Security

- **ğŸ  Local-First**: All processing happens on your device
- **ğŸš« No Telemetry**: Zero data collection or tracking
- **ğŸ”“ Open Source**: Complete transparency in code and behavior
- **ğŸ›¡ï¸ Secure**: Tauri's security model protects against vulnerabilities
- **ğŸ“ Data Control**: You own and control all conversations and documents

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

Special thanks to these incredible projects that make SparrowAI possible:

- **[Intel OpenVINO Model Server](https://github.com/openvinotoolkit/model_server)** - Local LLM Provider
- **[Tauri](https://tauri.app/)** - Secure cross-platform desktop framework
- **[Hugging Face](https://huggingface.co/)** - Democratizing access to AI models
- **[Material-UI](https://mui.com/)** - Beautiful React component library

---

<div align="center">
  
  **Built with â¤ï¸ by the SparrowAI team**
  
  <p>
    <a href="https://github.com/zhengchy95/SparrowAI">â­ Star on GitHub</a> â€¢
    <a href="https://github.com/zhengchy95/SparrowAI/issues">ğŸ› Report Issues</a> â€¢
    <a href="https://github.com/zhengchy95/SparrowAI/discussions">ğŸ’¬ Discussions</a>
  </p>
  
  <sub>Made possible by the open-source community ğŸŒŸ</sub>
  
</div>
